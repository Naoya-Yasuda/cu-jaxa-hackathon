{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: 東北3県 クマ目撃データ × JAXA衛星データ（偏相関分析含む）\n",
    "\n",
    "## 目的\n",
    "- 東北3県（秋田、岩手、福島）の熊目撃データをJAXA衛星データと統合\n",
    "- 時系列相関分析により、衛星指標（NDVI, GSMaP, LST）と目撃件数の関係を把握\n",
    "- **偏相関分析により季節性の交絡を除去し、衛星データの真の予測力を評価**\n",
    "- 空間分析により、目撃地点の地形・植生・土地被覆特性を把握\n",
    "- 機械学習モデル構築への示唆を導出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from config import BBOX, JAXA_DIR, SIGHTINGS_CSV, DATE_START, DATE_END\n",
    "\n",
    "# Set up matplotlib for Japanese text\n",
    "plt.rcParams['font.family'] = ['Hiragino Sans', 'IPAGothic', 'Noto Sans CJK JP', 'DejaVu Sans']\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(f\"Config loaded:\")\n",
    "print(f\"  BBOX: {BBOX}\")\n",
    "print(f\"  JAXA_DIR: {JAXA_DIR}\")\n",
    "print(f\"  SIGHTINGS_CSV: {SIGHTINGS_CSV}\")\n",
    "print(f\"  DATE_START: {DATE_START}, DATE_END: {DATE_END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 目撃データの基本統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Load sightings data\nprint(f\"Loading sightings from: {SIGHTINGS_CSV}\")\n\ntry:\n    df_sightings = pd.read_csv(SIGHTINGS_CSV, encoding='utf-8-sig')\n    df_sightings['date'] = pd.to_datetime(df_sightings['date'])\n    df_sightings = df_sightings.sort_values('date').reset_index(drop=True)\n    \n    print(f\"\\n=== 目撃データ基本統計 ===\")\n    print(f\"総件数: {len(df_sightings)}\")\n    print(f\"日付範囲: {df_sightings['date'].min()} ～ {df_sightings['date'].max()}\")\n    print(f\"緯度範囲: {df_sightings['lat'].min():.2f} ～ {df_sightings['lat'].max():.2f}\")\n    print(f\"経度範囲: {df_sightings['lon'].min():.2f} ～ {df_sightings['lon'].max():.2f}\")\n    \n    print(f\"\\n=== 県別内訳 ===\")\n    print(df_sightings['prefecture'].value_counts())\n    \n    print(f\"\\n=== 目撃タイプ内訳 ===\")\n    print(df_sightings['type'].value_counts())\n    \n    print(f\"\\n=== 先頭5行 ===\")\n    print(df_sightings.head())\n    \nexcept Exception as e:\n    print(f\"Error loading sightings: {e}\")\n    import traceback; traceback.print_exc()\n    df_sightings = pd.DataFrame()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Monthly sightings bar chart and prefecture comparison\n",
    "if len(df_sightings) > 0:\n",
    "    # Create monthly aggregates\n",
    "    df_sightings['year_month'] = df_sightings['date'].dt.to_period('M')\n",
    "    sighting_monthly = df_sightings.groupby('year_month').size()\n",
    "    sighting_monthly_pref = df_sightings.groupby(['year_month', 'prefecture']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Monthly time series\n",
    "    axes[0].bar(range(len(sighting_monthly)), sighting_monthly.values, color='steelblue', alpha=0.7)\n",
    "    axes[0].set_xlabel('月')\n",
    "    axes[0].set_ylabel('目撃件数')\n",
    "    axes[0].set_title('月別目撃件数（全県合計）')\n",
    "    axes[0].set_xticks(range(0, len(sighting_monthly), max(1, len(sighting_monthly)//12)))\n",
    "    axes[0].set_xticklabels([str(m) for m in sighting_monthly.index[::max(1, len(sighting_monthly)//12)]], rotation=45)\n",
    "    \n",
    "    # Prefecture stacked bar\n",
    "    sighting_monthly_pref.plot(kind='bar', stacked=True, ax=axes[1], \n",
    "                               color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    axes[1].set_xlabel('月')\n",
    "    axes[1].set_ylabel('目撃件数')\n",
    "    axes[1].set_title('月別目撃件数（県別積み上げ）')\n",
    "    axes[1].set_xticklabels([str(m) for m in sighting_monthly_pref.index], rotation=45)\n",
    "    axes[1].legend(title='県', loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"月別目撃件数統計:\")\n",
    "    print(f\"  平均: {sighting_monthly.mean():.2f}, 中央値: {sighting_monthly.median():.0f}, 最大: {sighting_monthly.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Spatial distribution scatter plot with BBOX rectangle\n",
    "if len(df_sightings) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Plot sightings colored by prefecture\n",
    "    prefectures = df_sightings['prefecture'].unique()\n",
    "    colors = {'秋田県': '#1f77b4', '岩手県': '#ff7f0e', '福島県': '#2ca02c'}\n",
    "    \n",
    "    for pref in prefectures:\n",
    "        mask = df_sightings['prefecture'] == pref\n",
    "        ax.scatter(df_sightings[mask]['lon'], df_sightings[mask]['lat'], \n",
    "                  label=pref, alpha=0.6, s=50, color=colors.get(pref, 'gray'))\n",
    "    \n",
    "    # Draw BBOX rectangle\n",
    "    from matplotlib.patches import Rectangle\n",
    "    rect = Rectangle((BBOX[0], BBOX[1]), BBOX[2]-BBOX[0], BBOX[3]-BBOX[1], \n",
    "                     linewidth=2, edgecolor='red', facecolor='none', linestyle='--', \n",
    "                     label='BBOX')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_xlabel('経度')\n",
    "    ax.set_ylabel('緯度')\n",
    "    ax.set_title('目撃地点の空間分布')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 県別分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Prefecture comparison\n",
    "if len(df_sightings) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Monthly distribution per prefecture\n",
    "    for pref in prefectures:\n",
    "        mask = df_sightings['prefecture'] == pref\n",
    "        monthly_pref = df_sightings[mask].groupby('year_month').size()\n",
    "        axes[0, 0].plot(range(len(monthly_pref)), monthly_pref.values, marker='o', label=pref)\n",
    "    axes[0, 0].set_xlabel('月')\n",
    "    axes[0, 0].set_ylabel('目撃件数')\n",
    "    axes[0, 0].set_title('県別月次推移')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Type distribution per prefecture\n",
    "    type_pref = df_sightings.groupby(['prefecture', 'type']).size().unstack(fill_value=0)\n",
    "    type_pref.T.plot(kind='bar', ax=axes[0, 1], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    axes[0, 1].set_xlabel('目撃タイプ')\n",
    "    axes[0, 1].set_ylabel('件数')\n",
    "    axes[0, 1].set_title('県別・タイプ別分布')\n",
    "    axes[0, 1].legend(title='県')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Total counts per prefecture\n",
    "    pref_counts = df_sightings['prefecture'].value_counts()\n",
    "    axes[1, 0].bar(pref_counts.index, pref_counts.values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    axes[1, 0].set_ylabel('総件数')\n",
    "    axes[1, 0].set_title('県別総件数')\n",
    "    for i, v in enumerate(pref_counts.values):\n",
    "        axes[1, 0].text(i, v + 5, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # Spatial density (points per prefecture)\n",
    "    for pref in prefectures:\n",
    "        mask = df_sightings['prefecture'] == pref\n",
    "        axes[1, 1].hist(df_sightings[mask]['lat'], alpha=0.5, label=pref, bins=20)\n",
    "    axes[1, 1].set_xlabel('緯度')\n",
    "    axes[1, 1].set_ylabel('度数')\n",
    "    axes[1, 1].set_title('県別・緯度分布')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== 県別統計 ===\")\n",
    "    for pref in prefectures:\n",
    "        mask = df_sightings['prefecture'] == pref\n",
    "        print(f\"{pref}: {mask.sum()} 件, 平均緯度 {df_sightings[mask]['lat'].mean():.2f}, 平均経度 {df_sightings[mask]['lon'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 衛星データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Load JAXA data function and load all datasets\n",
    "def load_jaxa_data(name):\n",
    "    \"\"\"Load JAXA data (images and metadata)\"\"\"\n",
    "    data_dir = JAXA_DIR / name\n",
    "    meta_path = data_dir / 'metadata.json'\n",
    "    \n",
    "    if not meta_path.exists():\n",
    "        print(f\"Warning: {meta_path} not found\")\n",
    "        return None, None\n",
    "    \n",
    "    with open(meta_path) as f:\n",
    "        meta = json.load(f)\n",
    "    \n",
    "    images = []\n",
    "    for i in range(meta['n_images']):\n",
    "        npy_path = data_dir / f\"{name}_{i:03d}.npy\"\n",
    "        if npy_path.exists():\n",
    "            images.append(np.load(npy_path))\n",
    "        else:\n",
    "            print(f\"Warning: {npy_path} not found\")\n",
    "    \n",
    "    return images, meta\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "dataset_names = ['ndvi_monthly', 'dem', 'fnf', 'gsmap_monthly', 'lst_monthly', 'landcover']\n",
    "\n",
    "for name in dataset_names:\n",
    "    print(f\"Loading {name}...\")\n",
    "    images, meta = load_jaxa_data(name)\n",
    "    if images is not None and len(images) > 0:\n",
    "        datasets[name] = {'images': images, 'meta': meta}\n",
    "        print(f\"  ✓ Loaded {len(images)} images, shape: {images[0].shape}\")\n",
    "    else:\n",
    "        print(f\"  ✗ Failed to load {name}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 時系列相関分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: Create monthly time series for satellite data\ndef generate_monthly_dates(meta):\n    \"\"\"Generate monthly date index from metadata dates\"\"\"\n    if 'dates' in meta:\n        dates = [pd.to_datetime(d) for d in meta['dates']]\n    elif 'start_date' in meta and 'end_date' in meta:\n        start = pd.to_datetime(meta['start_date'])\n        end = pd.to_datetime(meta['end_date'])\n        dates = pd.date_range(start, end, periods=meta['n_images'], freq='MS')\n    else:\n        # Fallback: assume monthly sequence\n        dates = pd.date_range(DATE_START, periods=meta['n_images'], freq='MS')\n    return pd.PeriodIndex(dates, freq='M')\n\n# Generate monthly time series for satellite data (use nanmean to handle NaN pixels)\nmonthly_ts = {}\n\nif 'ndvi_monthly' in datasets:\n    ndvi_meta = datasets['ndvi_monthly']['meta']\n    ndvi_images = datasets['ndvi_monthly']['images']\n    ndvi_dates = generate_monthly_dates(ndvi_meta)\n    ndvi_mean = np.array([np.nanmean(img) for img in ndvi_images])\n    monthly_ts['ndvi'] = {'dates': ndvi_dates, 'values': ndvi_mean}\n    nan_count = np.isnan(ndvi_mean).sum()\n    print(f\"NDVI: {len(ndvi_images)} months, dates from {ndvi_dates[0]} to {ndvi_dates[-1]}, NaN months: {nan_count}\")\n\nif 'gsmap_monthly' in datasets:\n    gsmap_meta = datasets['gsmap_monthly']['meta']\n    gsmap_images = datasets['gsmap_monthly']['images']\n    gsmap_dates = generate_monthly_dates(gsmap_meta)\n    gsmap_mean = np.array([np.nanmean(img) for img in gsmap_images])\n    monthly_ts['gsmap'] = {'dates': gsmap_dates, 'values': gsmap_mean}\n    nan_count = np.isnan(gsmap_mean).sum()\n    print(f\"GSMaP: {len(gsmap_images)} months, dates from {gsmap_dates[0]} to {gsmap_dates[-1]}, NaN months: {nan_count}\")\n\nif 'lst_monthly' in datasets:\n    lst_meta = datasets['lst_monthly']['meta']\n    lst_images = datasets['lst_monthly']['images']\n    lst_dates = generate_monthly_dates(lst_meta)\n    lst_mean = np.array([np.nanmean(img) for img in lst_images])\n    monthly_ts['lst'] = {'dates': lst_dates, 'values': lst_mean}\n    nan_count = np.isnan(lst_mean).sum()\n    print(f\"LST: {len(lst_images)} months, dates from {lst_dates[0]} to {lst_dates[-1]}, NaN months: {nan_count}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Time series plot (4 panels)\n",
    "if len(df_sightings) > 0 and len(monthly_ts) > 0:\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Sightings\n",
    "    axes[0].bar(range(len(sighting_monthly)), sighting_monthly.values, color='steelblue', alpha=0.7)\n",
    "    axes[0].set_ylabel('目撃件数')\n",
    "    axes[0].set_title('月別目撃件数')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # NDVI\n",
    "    if 'ndvi' in monthly_ts:\n",
    "        axes[1].plot(range(len(monthly_ts['ndvi']['values'])), monthly_ts['ndvi']['values'], \n",
    "                    marker='o', color='green', label='NDVI')\n",
    "        axes[1].set_ylabel('NDVI (平均値)')\n",
    "        axes[1].set_title('月別NDVI')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # LST\n",
    "    if 'lst' in monthly_ts:\n",
    "        axes[2].plot(range(len(monthly_ts['lst']['values'])), monthly_ts['lst']['values'], \n",
    "                    marker='s', color='red', label='LST')\n",
    "        axes[2].set_ylabel('LST (K, 平均値)')\n",
    "        axes[2].set_title('月別地表面温度')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # GSMaP\n",
    "    if 'gsmap' in monthly_ts:\n",
    "        axes[3].plot(range(len(monthly_ts['gsmap']['values'])), monthly_ts['gsmap']['values'], \n",
    "                    marker='^', color='blue', label='GSMaP')\n",
    "        axes[3].set_ylabel('GSMaP (mm/month, 平均値)')\n",
    "        axes[3].set_xlabel('月')\n",
    "        axes[3].set_title('月別降水量')\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 13: Pearson/Spearman correlation table\nif len(df_sightings) > 0 and len(monthly_ts) > 0:\n    # Rebuild monthly sightings from raw data to avoid any Cell 4 side effects\n    _sighting_ym = df_sightings['date'].dt.to_period('M')\n    _sighting_counts = df_sightings.groupby(_sighting_ym).size()\n    \n    # Debug info\n    print(f\"[DEBUG] sighting months: {len(_sighting_counts)}, first={_sighting_counts.index[0]}, last={_sighting_counts.index[-1]}\")\n    for k in monthly_ts:\n        print(f\"[DEBUG] {k} months: {len(monthly_ts[k]['dates'])}, first={monthly_ts[k]['dates'][0]}, last={monthly_ts[k]['dates'][-1]}\")\n    \n    # Use string-based alignment\n    sighting_dict = {str(p): v for p, v in zip(_sighting_counts.index, _sighting_counts.values)}\n    \n    all_data = {}\n    for var_name in ['ndvi', 'gsmap', 'lst']:\n        if var_name in monthly_ts:\n            sat_dict = {str(p): v for p, v in zip(monthly_ts[var_name]['dates'], monthly_ts[var_name]['values'])}\n            all_data[var_name] = sat_dict\n    \n    # Find common months across all\n    common_months = set(sighting_dict.keys())\n    for var_name in all_data:\n        common_months &= set(all_data[var_name].keys())\n    common_months = sorted(common_months)\n    \n    print(f\"[DEBUG] common months: {len(common_months)}\")\n    \n    # Build corr_data\n    corr_data = pd.DataFrame({\n        'sightings': [sighting_dict[m] for m in common_months],\n        **{var_name: [all_data[var_name][m] for m in common_months] for var_name in all_data}\n    }, index=common_months)\n    common_dates = corr_data.index\n    \n    print(f\"\\n=== 時系列相関分析（未調整） ===\")\n    print(f\"サンプル期間: {len(common_dates)} ヶ月\", end=\"\")\n    if len(common_dates) > 0:\n        print(f\" ({common_dates[0]} ～ {common_dates[-1]})\")\n    else:\n        print(\" (共通期間なし)\")\n    \n    if len(corr_data) > 1:\n        print(f\"\\nピアソン相関:\")\n        pearson_corr = corr_data.corr(method='pearson')\n        print(pearson_corr['sightings'].drop('sightings'))\n        \n        print(f\"\\nスピアマン相関:\")\n        spearman_corr = corr_data.corr(method='spearman')\n        print(spearman_corr['sightings'].drop('sightings'))\n        \n        # P-value calculation\n        print(f\"\\nP値（ピアソン相関）:\")\n        for col in corr_data.columns:\n            if col != 'sightings':\n                r, p = stats.pearsonr(corr_data['sightings'], corr_data[col])\n                print(f\"  {col}: r={r:.4f}, p={p:.4f} {'***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''}\")\n    else:\n        print(\"相関分析に十分なデータがありません\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 14: Scatter plots (NDVI vs sightings, GSMaP vs sightings, LST vs sightings)\nif len(df_sightings) > 0 and 'corr_data' in dir() and len(corr_data) > 1:\n    sat_vars = [v for v in ['ndvi', 'gsmap', 'lst'] if v in corr_data.columns]\n    n_cols = len(sat_vars)\n    if n_cols > 0:\n        fig, axes = plt.subplots(1, n_cols, figsize=(14, 4))\n        if n_cols == 1:\n            axes = [axes]\n        \n        for idx, var_name in enumerate(sat_vars):\n            x_data = np.array(corr_data[var_name].tolist(), dtype=float)\n            y_data = np.array(corr_data['sightings'].tolist(), dtype=float)\n            \n            # Filter out NaN/Inf\n            mask = np.isfinite(x_data) & np.isfinite(y_data)\n            x_clean, y_clean = x_data[mask], y_data[mask]\n            \n            if len(x_clean) < 2:\n                axes[idx].set_title(f\"{var_name.upper()} vs 目撃件数 (データ不足)\")\n                continue\n            \n            axes[idx].scatter(x_clean, y_clean, alpha=0.6, s=50)\n            \n            # Add trend line\n            try:\n                z = np.polyfit(x_clean, y_clean, 1)\n                p_line = np.poly1d(z)\n                x_sorted = np.sort(x_clean)\n                axes[idx].plot(x_sorted, p_line(x_sorted), \"r--\", alpha=0.8, linewidth=2)\n            except Exception:\n                pass\n            \n            r, p_val = stats.pearsonr(x_clean, y_clean)\n            axes[idx].set_xlabel(f\"{var_name.upper()} (平均値)\")\n            axes[idx].set_ylabel('目撃件数')\n            axes[idx].set_title(f\"{var_name.upper()} vs 目撃件数 (r={r:.3f}, p={p_val:.3f})\")\n            axes[idx].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 偏相関分析（★重要：季節性の交絡検証）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 16: Partial correlation analysis - KEY ANALYSIS FOR P4 ISSUE\ndef partial_correlation(x, y, z_categorical):\n    \"\"\"偏相関係数を計算 (x と y の相関から、カテゴリ変数 z の影響を除去)\"\"\"\n    from numpy.linalg import lstsq\n    \n    z_dummies = pd.get_dummies(z_categorical, drop_first=True).values.astype(float)\n    \n    if z_dummies.shape[1] > 0:\n        beta_x, _, _, _ = lstsq(z_dummies, x, rcond=None)\n        resid_x = x - z_dummies @ beta_x\n        beta_y, _, _, _ = lstsq(z_dummies, y, rcond=None)\n        resid_y = y - z_dummies @ beta_y\n    else:\n        resid_x, resid_y = x, y\n    \n    r, p = stats.pearsonr(resid_x, resid_y)\n    return r, p\n\n# Use corr_data from Cell 13 (already aligned)\nif len(df_sightings) > 0 and 'corr_data' in dir() and len(corr_data) > 1:\n    partial_corr_results = {}\n    \n    # Extract month from string index (format: \"2022-04\")\n    month_values = [int(d.split('-')[1]) for d in corr_data.index]\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"偏相関分析: 季節性（月）の影響を統制した分析\")\n    print(\"=\"*70)\n    print(f\"\\n分析対象期間: {len(corr_data)} ヶ月 ({corr_data.index[0]} ～ {corr_data.index[-1]})\")\n    print(f\"月別目撃件数: 平均 {corr_data['sightings'].mean():.2f}, 中央値 {corr_data['sightings'].median():.1f}\")\n    \n    for var_name, var_label in [('ndvi', 'NDVI'), ('gsmap', 'GSMaP'), ('lst', 'LST')]:\n        if var_name not in corr_data.columns:\n            continue\n            \n        print(f\"\\n--- {var_label} × 目撃件数 ---\")\n        r_raw, p_raw = stats.pearsonr(corr_data[var_name], corr_data['sightings'])\n        r_partial, p_partial = partial_correlation(\n            corr_data[var_name].values,\n            corr_data['sightings'].values,\n            np.array(month_values)\n        )\n        \n        print(f\"  単純相関（未調整）:   r = {r_raw:7.4f}, p = {p_raw:.4f} {'***' if p_raw < 0.001 else '**' if p_raw < 0.01 else '*' if p_raw < 0.05 else ''}\")\n        print(f\"  偏相関（月を統制）:   r = {r_partial:7.4f}, p = {p_partial:.4f} {'***' if p_partial < 0.001 else '**' if p_partial < 0.01 else '*' if p_partial < 0.05 else ''}\")\n        \n        decay = abs(r_raw) - abs(r_partial)\n        decay_pct = 100 * decay / abs(r_raw) if abs(r_raw) > 0 else 0\n        print(f\"  相関強度の変化: {-decay:+.4f} ({decay_pct:.1f}% 低下)\")\n        \n        if abs(r_partial) < abs(r_raw) * 0.5:\n            print(f\"  ⚠  解釈: 月を統制すると相関が大幅に低下。季節性による擬似相関の可能性が高い。\")\n        elif abs(r_partial) > 0.3:\n            print(f\"  ✓  解釈: 月を統制しても相関が残存。季節性を超えた追加的な予測力あり。\")\n        else:\n            print(f\"  ➜  解釈: 相関が弱い。追加検討が必要。\")\n        \n        partial_corr_results[var_name] = {'raw': (r_raw, p_raw), 'partial': (r_partial, p_partial)}\n    \n    print(\"\\n\" + \"=\"*70)\nelse:\n    partial_corr_results = {}\n    print(\"偏相関分析: データ不足のためスキップ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Visualization comparing raw vs partial correlations\n",
    "if len(df_sightings) > 0 and len(partial_corr_results) > 0:\n",
    "    # Prepare data for comparison\n",
    "    variables = list(partial_corr_results.keys())\n",
    "    raw_corrs = [partial_corr_results[v]['raw'][0] for v in variables]\n",
    "    partial_corrs = [partial_corr_results[v]['partial'][0] for v in variables]\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Correlation comparison bar chart\n",
    "    x = np.arange(len(variables))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, raw_corrs, width, label='単純相関（未調整）', alpha=0.8, color='steelblue')\n",
    "    ax1.bar(x + width/2, partial_corrs, width, label='偏相関（月を統制）', alpha=0.8, color='coral')\n",
    "    ax1.set_ylabel('相関係数')\n",
    "    ax1.set_title('相関係数の比較: 生データ vs 月を統制した場合')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([v.upper() for v in variables])\n",
    "    ax1.legend()\n",
    "    ax1.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Relative change in correlation magnitude\n",
    "    relative_change = [(partial_corrs[i] - raw_corrs[i]) / abs(raw_corrs[i]) if raw_corrs[i] != 0 else 0 \n",
    "                       for i in range(len(variables))]\n",
    "    colors = ['green' if c < -0.2 else 'orange' if -0.2 <= c <= 0.2 else 'red' for c in relative_change]\n",
    "    \n",
    "    ax2.bar(x, relative_change, color=colors, alpha=0.7)\n",
    "    ax2.set_ylabel('相関強度の相対変化')\n",
    "    ax2.set_title('月統制による相関強度の変化\\n（緑=大幅低下→季節性の擬似相関, 赤=増加→月による負の交絡）')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels([v.upper() for v in variables])\n",
    "    ax2.axhline(y=0, color='k', linestyle='-', linewidth=1)\n",
    "    ax2.axhline(y=-0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='大幅低下の閾値 (-50%)')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n解釈ガイド:\")\n",
    "    print(\"  - 緑色: 偏相関が単純相関より大幅に低い → 季節性による擬似相関の可能性が高い\")\n",
    "    print(\"  - オレンジ: 相関強度がほぼ変わらない → 季節性と独立した効果\")\n",
    "    print(\"  - 赤色: 偏相関が単純相関より高い → 月による負の交絡（考慮すべき）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 空間分析: 目撃地点の衛星特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 19: Extract elevation/fnf/landcover for each sighting\ndef latlon_to_pixel(lat, lon, img_shape, bbox=BBOX):\n    \"\"\"Convert lat/lon to pixel coordinates within BBOX\"\"\"\n    if lon < bbox[0] or lon > bbox[2] or lat < bbox[1] or lat > bbox[3]:\n        return None, None\n    \n    rows, cols = img_shape[0], img_shape[1]\n    norm_lon = (lon - bbox[0]) / (bbox[2] - bbox[0])\n    norm_lat = (bbox[3] - lat) / (bbox[3] - bbox[1])  # top=north\n    \n    col = int(norm_lon * cols)\n    row = int(norm_lat * rows)\n    \n    if 0 <= row < rows and 0 <= col < cols:\n        return row, col\n    return None, None\n\nif len(df_sightings) > 0:\n    # DEM\n    if 'dem' in datasets and len(datasets['dem']['images']) > 0:\n        dem_img = datasets['dem']['images'][0][:, :, 0]\n        dem_vals = []\n        for _, row in df_sightings.iterrows():\n            r, c = latlon_to_pixel(row['lat'], row['lon'], dem_img.shape)\n            dem_vals.append(dem_img[r, c] if r is not None else np.nan)\n        df_sightings['elevation'] = dem_vals\n        print(f\"DEM: {sum(1 for v in dem_vals if not np.isnan(v))}/{len(dem_vals)} 件にマッチ\")\n\n    # FNF\n    if 'fnf' in datasets and len(datasets['fnf']['images']) > 0:\n        fnf_img = datasets['fnf']['images'][0][:, :, 0]\n        fnf_vals = []\n        for _, row in df_sightings.iterrows():\n            r, c = latlon_to_pixel(row['lat'], row['lon'], fnf_img.shape)\n            fnf_vals.append(int(fnf_img[r, c]) if r is not None else np.nan)\n        df_sightings['fnf'] = fnf_vals\n        print(f\"FNF: 森林={sum(1 for v in fnf_vals if v == 1)}件\")\n\n    # Landcover\n    if 'landcover' in datasets and len(datasets['landcover']['images']) > 0:\n        lc_img = datasets['landcover']['images'][0][:, :, 0]\n        lc_vals = []\n        for _, row in df_sightings.iterrows():\n            r, c = latlon_to_pixel(row['lat'], row['lon'], lc_img.shape)\n            lc_vals.append(int(lc_img[r, c]) if r is not None else np.nan)\n        df_sightings['landcover'] = lc_vals\n\n    print(f\"\\n=== 目撃地点の空間特性 ===\")\n    if 'elevation' in df_sightings.columns:\n        print(f\"標高: 平均 {df_sightings['elevation'].mean():.1f}m, 中央値 {df_sightings['elevation'].median():.1f}m\")\n        print(f\"      範囲 {df_sightings['elevation'].min():.1f}m ～ {df_sightings['elevation'].max():.1f}m\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Elevation histogram, FNF classification bar, landcover distribution\n",
    "if len(df_sightings) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Elevation histogram\n",
    "    if 'elevation' in df_sightings.columns:\n",
    "        axes[0, 0].hist(df_sightings['elevation'].dropna(), bins=30, color='brown', alpha=0.7, edgecolor='black')\n",
    "        axes[0, 0].set_xlabel('標高 (m)')\n",
    "        axes[0, 0].set_ylabel('度数')\n",
    "        axes[0, 0].set_title('目撃地点の標高分布')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # FNF classification\n",
    "    if 'fnf' in df_sightings.columns:\n",
    "        fnf_counts = df_sightings['fnf'].value_counts().sort_index()\n",
    "        fnf_labels = {0: '非森林', 1: '森林', 2: '不確定'}\n",
    "        axes[0, 1].bar([fnf_labels.get(i, f'{i}') for i in fnf_counts.index], fnf_counts.values, \n",
    "                       color=['#ff7f0e', '#2ca02c', '#d62728'], alpha=0.7)\n",
    "        axes[0, 1].set_ylabel('件数')\n",
    "        axes[0, 1].set_title('目撃地点の森林分類')\n",
    "        axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Prefecture vs elevation\n",
    "    if 'elevation' in df_sightings.columns:\n",
    "        for pref in df_sightings['prefecture'].unique():\n",
    "            mask = df_sightings['prefecture'] == pref\n",
    "            axes[1, 0].boxplot(df_sightings[mask]['elevation'].dropna(), label=pref, positions=[list(df_sightings['prefecture'].unique()).index(pref)])\n",
    "        axes[1, 0].set_xticklabels(df_sightings['prefecture'].unique())\n",
    "        axes[1, 0].set_ylabel('標高 (m)')\n",
    "        axes[1, 0].set_title('県別標高分布')\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Landcover distribution\n",
    "    if 'landcover' in df_sightings.columns:\n",
    "        lc_counts = df_sightings['landcover'].value_counts().sort_index()\n",
    "        lc_labels = {1: '水域', 2: '市街地', 3: '農地', 4: '草地', 5: '森林', 6: '岩石/雪', 0: 'その他'}\n",
    "        axes[1, 1].bar([lc_labels.get(i, f'LC{i}') for i in lc_counts.index], lc_counts.values, \n",
    "                       color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'], alpha=0.7)\n",
    "        axes[1, 1].set_ylabel('件数')\n",
    "        axes[1, 1].set_title('目撃地点の土地被覆')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Month vs elevation scatter (seasonal altitudinal migration)\n",
    "if len(df_sightings) > 0 and 'elevation' in df_sightings.columns:\n",
    "    df_sightings['month'] = df_sightings['date'].dt.month\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Scatter plot\n",
    "    scatter = axes[0].scatter(df_sightings['month'], df_sightings['elevation'], \n",
    "                             c=df_sightings['month'], cmap='coolwarm', alpha=0.6, s=50)\n",
    "    axes[0].set_xlabel('月')\n",
    "    axes[0].set_ylabel('標高 (m)')\n",
    "    axes[0].set_title('季節による標高分布の変化')\n",
    "    axes[0].set_xticks(range(1, 13))\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=axes[0], label='月')\n",
    "    \n",
    "    # Monthly median elevation\n",
    "    monthly_elev = df_sightings.groupby('month')['elevation'].agg(['mean', 'median', 'std'])\n",
    "    axes[1].plot(monthly_elev.index, monthly_elev['median'], marker='o', label='中央値', linewidth=2, color='steelblue')\n",
    "    axes[1].fill_between(monthly_elev.index, \n",
    "                         monthly_elev['median'] - monthly_elev['std'],\n",
    "                         monthly_elev['median'] + monthly_elev['std'],\n",
    "                         alpha=0.3, color='steelblue', label='±1SD')\n",
    "    axes[1].set_xlabel('月')\n",
    "    axes[1].set_ylabel('標高 (m)')\n",
    "    axes[1].set_title('月別平均標高の推移')\n",
    "    axes[1].set_xticks(range(1, 13))\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical test\n",
    "    print(\"\\n=== 季節による標高変化の検定 ===\")\n",
    "    # ANOVA\n",
    "    groups = [df_sightings[df_sightings['month'] == m]['elevation'].dropna().values for m in range(1, 13)]\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    f_stat, p_val = stats.f_oneway(*groups)\n",
    "    print(f\"一元配置分散分析: F={f_stat:.4f}, p={p_val:.4f}\")\n",
    "    if p_val < 0.05:\n",
    "        print(\"→ 月間の標高分布に有意差あり（季節的な高度移動の可能性）\")\n",
    "    else:\n",
    "        print(\"→ 月間の標高分布に有意差なし\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ラスタデータ可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 23: 2x3 grid showing DEM, FNF, Landcover, NDVI(summer), NDVI(winter), NDVI diff\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\nextent = [BBOX[0], BBOX[2], BBOX[1], BBOX[3]]\n\ndef plot_raster(ax, img, title, cmap='viridis'):\n    # Squeeze band dimension if present\n    if img.ndim == 3:\n        img = img[:, :, 0]\n    im = ax.imshow(img, cmap=cmap, aspect='auto', extent=extent)\n    ax.set_title(title, fontsize=12, fontweight='bold')\n    plt.colorbar(im, ax=ax, shrink=0.8)\n\n# Row 1: Static datasets\nif 'dem' in datasets:\n    plot_raster(axes[0, 0], datasets['dem']['images'][0], 'DEM (標高)', cmap='terrain')\nif 'fnf' in datasets:\n    plot_raster(axes[0, 1], datasets['fnf']['images'][0], 'FNF (森林分類)', cmap='RdYlGn')\nif 'landcover' in datasets:\n    plot_raster(axes[0, 2], datasets['landcover']['images'][0], '土地被覆分類', cmap='tab20')\n\n# Row 2: NDVI temporal\nif 'ndvi_monthly' in datasets:\n    imgs = datasets['ndvi_monthly']['images']\n    # Summer = index 3 (Jul of first year: Apr=0, May=1, Jun=2, Jul=3)\n    summer_idx = min(3, len(imgs)-1)\n    # Winter = index 9 (Jan of 2nd year: ... Oct=6, Nov=7, Dec=8, Jan=9)  \n    winter_idx = min(9, len(imgs)-1)\n    plot_raster(axes[1, 0], imgs[summer_idx], f'NDVI (夏: idx={summer_idx})', cmap='YlGn')\n    plot_raster(axes[1, 1], imgs[winter_idx], f'NDVI (冬: idx={winter_idx})', cmap='YlGn')\n    ndvi_diff = imgs[summer_idx][:,:,0] - imgs[winter_idx][:,:,0]\n    im = axes[1, 2].imshow(ndvi_diff, cmap='RdBu_r', aspect='auto', extent=extent)\n    axes[1, 2].set_title('NDVI差分 (夏-冬)', fontsize=12, fontweight='bold')\n    plt.colorbar(im, ax=axes[1, 2], shrink=0.8)\n\n# Overlay sighting points\nfor ax in axes.flatten():\n    if len(df_sightings) > 0:\n        ax.scatter(df_sightings['lon'], df_sightings['lat'], c='red', s=2, alpha=0.15)\n    ax.set_xlabel('経度')\n    ax.set_ylabel('緯度')\n\nplt.suptitle('衛星ラスタデータの可視化 (赤点=目撃地点)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 総合サマリ & モデルへの示唆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Comprehensive summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"東北3県 クマ目撃データ × JAXA衛星データ EDA サマリレポート\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n【1】データ概要\")\n",
    "print(\"-\" * 80)\n",
    "if len(df_sightings) > 0:\n",
    "    print(f\"目撃件数: {len(df_sightings)} 件\")\n",
    "    print(f\"期間: {df_sightings['date'].min().date()} ～ {df_sightings['date'].max().date()}\")\n",
    "    print(f\"地域: {', '.join(df_sightings['prefecture'].unique())}\")\n",
    "    print(f\"月別平均: {df_sightings.groupby('year_month').size().mean():.2f} 件/月\")\n",
    "    print(f\"地理的範囲: 北緯 {df_sightings['lat'].min():.2f}°～{df_sightings['lat'].max():.2f}°, \"\n",
    "          f\"東経 {df_sightings['lon'].min():.2f}°～{df_sightings['lon'].max():.2f}°\")\nelse:\n",
    "    print(\"目撃データが読み込まれていません\")\n\nprint(f\"\\n衛星データセット: {len(datasets)} 個が利用可能\")\nfor name in datasets.keys():\n    print(f\"  - {name}: {len(datasets[name]['images'])} 時点\")\n\nprint(\"\\n【2】時系列相関分析の結果\")\nprint(\"-\" * 80)\nif 'partial_corr_results' in locals() and len(partial_corr_results) > 0:\n    for var_name in ['ndvi', 'gsmap', 'lst']:\n        if var_name in partial_corr_results:\n            r_raw, p_raw = partial_corr_results[var_name]['raw']\n            r_partial, p_partial = partial_corr_results[var_name]['partial']\n            print(f\"\\n{var_name.upper()}:\")\n            print(f\"  単純相関（全変動考慮）: r = {r_raw:+.4f}, p = {p_raw:.4f}\")\n            print(f\"  偏相関（季節性控除）:  r = {r_partial:+.4f}, p = {p_partial:.4f}\")\n            \n            # Interpretation\n            decay_pct = 100 * (abs(r_raw) - abs(r_partial)) / abs(r_raw) if r_raw != 0 else 0\n            if decay_pct > 50:\n                print(f\"  解釈: 相関強度が {decay_pct:.0f}% 低下 → 季節性による擬似相関の可能性大\")\n            elif abs(r_partial) > 0.3:\n                print(f\"  解釈: 相関強度が {decay_pct:.0f}% 低下 → 季節性を超えた独立的な予測力あり\")\n            else:\n                print(f\"  解釈: 弱い相関。予測力に疑問。\")\nelse:\n    print(\"相関分析が未実行\")\n\nprint(\"\\n【3】★重要な知見: 季節性の交絡について\")\nprint(\"-\" * 80)\nprint(\"「NDVI(植生)が目撃件数と相関がある」という見かけの事実は、\")\nprint(\"実は単に『両方とも季節に依存している』ことの可能性が高い。\")\nprint(\"\\n偏相関分析により、この季節性の影響を除去することで、\")\nprint(\"衛星データの真の予測力を評価することができる。\")\nif 'partial_corr_results' in locals():\n    ndvi_has_power = partial_corr_results.get('ndvi', {}).get('partial', (0, 1))[0]\n    if abs(ndvi_has_power) > 0.2:\n        print(\"→ 本分析では、季節を統制してもNDVIの効果が残存している可能性がある。\")\n    else:\n        print(\"→ 本分析では、季節を統制するとNDVIの相関がほぼ消失する傾向が見られる。\")\n        print(\"   この場合、モデルに季節変数を明示的に含めることが重要。\")\n\nprint(\"\\n【4】空間的特性\")\nprint(\"-\" * 80)\nif 'elevation' in df_sightings.columns:\n    print(f\"目撃地点の標高: 平均 {df_sightings['elevation'].mean():.0f}m, \"\n          f\"範囲 {df_sightings['elevation'].min():.0f}m～{df_sightings['elevation'].max():.0f}m\")\n    \n    # Seasonal elevation pattern\n    monthly_elev = df_sightings.groupby('month')['elevation'].median()\n    if len(monthly_elev) > 1:\n        summer_elev = monthly_elev[summer_idx] if summer_idx in monthly_elev.index else monthly_elev.iloc[6] if len(monthly_elev) > 6 else monthly_elev.mean()\n        winter_elev = monthly_elev[1] if 1 in monthly_elev.index else monthly_elev.iloc[0]\n        if summer_elev > winter_elev:\n            print(f\"季節パターン: 夏季に高標高（平均{summer_elev:.0f}m）、\"\n                  f\"冬季に低標高（平均{winter_elev:.0f}m）\")\n            print(\"→ 季節的な高度移動パターンが示唆される（夏は山奥、冬は麓）\")\nelse:\n    print(\"標高データが利用不可\")\n\nif 'fnf' in df_sightings.columns:\n    forest_pct = (df_sightings['fnf'] == 1).sum() / len(df_sightings) * 100\n    print(f\"\\n森林地域での目撃: {forest_pct:.1f}%\")\n\nprint(\"\\n【5】機械学習モデルへの推奨事項\")\nprint(\"-\" * 80)\nprint(\"\\n1. 特徴量エンジニアリング:\")\nprint(\"   ✓ 季節変数（月、四半期など）を明示的に含める\")\nprint(\"   ✓ 季節-衛星指標の相互作用項を検討\")\nprint(\"   ✓ 移動平均・トレンド・周期パターンを抽出\")\n\nprint(\"\\n2. 衛星指標の活用:\")\nif 'partial_corr_results' in locals():\n    strong_predictors = [k for k, v in partial_corr_results.items() \n                        if abs(v['partial'][0]) > 0.2]\n    if strong_predictors:\n        print(f\"   ✓ 独立的な予測力を持つ指標: {', '.join(strong_predictors).upper()}\")\n    else:\n        print(\"   ⚠  注意: 衛星指標の独立的な予測力が弱い可能性\")\n        print(\"      → 季節ダミーやラグ変数の活用を重視\")\n\nprint(\"\\n3. 空間的特性の活用:\")\nprint(\"   ✓ 標高を予測変数に含める\")\nprint(\"   ✓ 森林密度（FNF）を含める\")\nprint(\"   ✓ 県別・市町村別の固定効果を検討\")\n\nprint(\"\\n4. モデル構築方針:\")\nprint(\"   ✓ ベースライン: 季節ダミー + トレンド\")\nprint(\"   ✓ 改善版1: ベースライン + 空間特性（標高、FNF）\")\nprint(\"   ✓ 改善版2: ベースライン + 衛星指標（NDVI, GSMaP, LST）\")\nprint(\"   ✓ フル版: 全特徴量を組み合わせ\")\nprint(\"      → 偏相関分析の結果に基づいて特徴量を厳選\")\n\nprint(\"\\n【6】次のステップ\")\nprint(\"-\" * 80)\nprint(\"  □ ラグ変数の導入（t-1, t-3, t-12月前のデータ）\")\nprint(\"  □ 異常値検出と外れ値処理\")\nprint(\"  □ 多重共線性の診断（VIF確認）\")\nprint(\"  □ 時系列分解（トレンド・季節性・残差の分離）\")\nprint(\"  □ 交差検証による予測性能評価\")\nprint(\"  □ 説明可能性分析（SHAP値など）\")\n\nprint(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}